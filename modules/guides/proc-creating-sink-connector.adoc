[id='proc-creating-sink-connector_{context}']
= Creating a Connectors instance for a data sink
:imagesdir: ../_images

[role="_abstract"]
A *sink* connector consumes messages from a Kafka topic and sends them to an external system.

For this example, you use the *HTTP Sink* connector which consumes the Kafka messages (produced by the source Connectors instance) and sends the messages to an HTTP endpoint.

ifndef::qs[]
.Prerequisites
* You're logged in to the OpenShift Application Services web console at {service-url-connectors}[^].
* You created the source Connectors instance as described in _{base-url}{getting-started-url-conectors}/proc-creating-source-connector_getting-started-connectors[Creating a Connectors instance for a data source^]_.
* For the data sink example, open the free https://webhook.site[Webhook.site^] in a browser window. The Webhook.site page provides a unique URL that you copy for use as an HTTP data sink.
endif::[]

.Procedure

. In the OpenShift Application Services web console, select *Connectors* and then click *Create Connectors instance*.

. Select the sink connector that you want to use:
.. For example, type *http* in the search field. The list of connectors filters to show the *HTTP Sink* connector.
.. Click the *HTTP Sink connector* card and then click *Next*.

. Select the {product-kafka} instance for the connector to work with.
+
For example, select *test*  and then click *Next*.

. On the *Namespace* page, click the *eval namespace* that you created when you created the source connector.

//. On the *Namespace* page, the namespace that you select depends on your OpenShift Dedicated environment.
//+
//If you are using a trial cluster on your own OpenShift Dedicated environment, select the card for the namespace that was created when you added the Connectors service to your trial cluster.
//+
//If you are using the evaluation OpenShift Dedicated environment, click the *eval namespace* that you created when you created the source connector.

. Click *Next*.

. Provide the core configuration for your connector:
.. Type a unique name for the connector.
.. Type the *Client ID* and *Client Secret* of the service account that you created for Connectors and then click *Next*.

. Provide the connector-specific configuration for your connector. For the *HTTP sink connector*, provide the following information:

.. *Data shape Format*: Accept the default, `application/octet-stream`.
.. *Method*: Accept the default, `POST`.
.. *URL*: Type your unique URL from the link:https://webhook.site[webhook.site^].
.. *Topic Names*: Type the name of the topic that you used for the source Connectors instance. For example, type *test-topic*.

. Optionally, configure the error handling policy for your Connectors instance. For example, select *log* and then click *Next*.

. Review the summary of the configuration properties and then click *Create Connectors instance*.
+
Your Connectors instance is listed in the table of Connectors.
+
After a couple of seconds, the status of your Connectors instance changes to the *Ready* state. It consumes messages from the associated Kafka topic and sends them to the data sink (for this example, the data sink is the HTTP URL that you provided).

.Verification

Open the browser tab to your custom URL for the link:https://webhook.site[webhook.site^] to see the HTTP POST calls with the `"Hello World!!"` messages (that you defined in the source connector).


ifdef::qs[]
[#conclusion]
Congratulations! You successfully completed the {product-long-connectors} Getting Started quick start.
endif::[]

ifdef::parent-context[:context: {parent-context}]
ifndef::parent-context[:!context:]
