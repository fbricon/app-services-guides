[id='assembly-getting-started-connectors']
= Getting started with {product-long-connectors}
ifdef::context[:parent-context: {context}]
:context: getting-started-connectors
:imagesdir: _images

// Purpose statement for the assembly
[role="_abstract"]
As a developer of applications and services, you can use {product-long-connectors} to create and configure connections between OpenShift Streams for Apache Kafka and third-party systems.

In this example, you connect a data source (a data generator) that creates Kafka messages and a data sink (an HTTP endpoint) that consumes the Kafka messages.

// Condition out QS-only content so that it doesn't appear in docs.
// All QS anchor IDs must be in this alternate anchor ID format `[#anchor-id]` because the ascii splitter relies on the other format `[id="anchor-id"]` to generate module files.
ifdef::qs[]
[#description]
Learn how to create and set up connectors in {product-long-connectors}.

[#introduction]
Welcome to the quick start for {product-long-connectors}.

In this quick start, you learn how to create a source connector and sink connector and send data to and from {product-kafka}.

A *source* connector allows you to send data from an external system to {product-kafka}. A *sink* connector allows you to send data from {product-kafka} to an external system.

endif::[]

ifndef::qs[]
== Overview

{product-long-kafka} is a cloud service that simplifies the process of running Apache Kafka. Apache Kafka is an open-source, distributed, publish-subscribe messaging system for creating fault-tolerant, real-time data feeds.

You can use {product-long-connectors} to configure communication between {product-kafka} instances and external services and applications. {product-long-connectors} allow you to configure how data moves from one endpoint to another without writing code.

The following diagram illustrates how data flows from a data source through a data source connector to a Kafka topic. And how data flows from a Kafka topic to a data sink through a data sink connector.

 [.screencapture]
.{product-long-connectors} data flow
image::connectors-getting-started-connectors/connectors-diagram.png[Illustration of data flow from data source through Kafka to data sink]

endif::[]

include::modules/guides/proc-configuring-kafka-for-connectors.adoc[leveloffset=+1]

include::modules/guides/proc-creating-source-connector.adoc[leveloffset=+1]

include::modules/guides/proc-creating-sink-connector.adoc[leveloffset=+1]

ifdef::qs[]
[#conclusion]
Congratulations! You successfully completed the {product-long-connectors} Getting Started quick start.
endif::[]
ifdef::parent-context[:context: {parent-context}]
ifndef::parent-context[:!context:]

